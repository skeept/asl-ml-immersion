name: Tune hyperparameters
inputs:
- {name: project, type: String}
- {name: location, type: String}
- {name: container_uri, type: String}
- {name: training_file_path, type: String}
- {name: validation_file_path, type: String}
- {name: staging_bucket, type: String}
- {name: max_trial_count, type: Integer}
- {name: parallel_trial_count, type: Integer}
outputs:
- {name: best_accuracy, type: Float}
- {name: best_alpha, type: Float}
- {name: best_max_iter, type: Integer}
implementation:
  container:
    image: python:3.8
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-aiplatform' 'kfp==1.8.10' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - |2+

      import kfp
      from kfp.v2 import dsl
      from kfp.v2.dsl import *
      from typing import *

      def tune_hyperparameters(
          project: str,
          location: str,
          container_uri: str,
          training_file_path: str,
          validation_file_path: str,
          staging_bucket: str,
          max_trial_count: int,
          parallel_trial_count: int,
      ) -> NamedTuple(
          "Outputs",
          [("best_accuracy", float), ("best_alpha", float), ("best_max_iter", int)],
      ):

          # pylint: disable=import-outside-toplevel
          from google.cloud import aiplatform

          # pylint: disable-next=unused-import
          from google.cloud.aiplatform import hyperparameter_tuning as hpt

          aiplatform.init(
              project=project, location=location, staging_bucket=staging_bucket
          )

          worker_pool_specs = [
              {
                  "machine_spec": {
                      "machine_type": "n1-standard-4",
                      "accelerator_type": "NVIDIA_TESLA_K80",
                      "accelerator_count": 1,
                  },
                  "replica_count": 1,
                  "container_spec": {
                      "image_uri": container_uri,
                      "args": [
                          f"--training_dataset_path={training_file_path}",
                          f"--validation_dataset_path={validation_file_path}",
                          "--hptune",
                      ],
                  },
              }
          ]

          custom_job = aiplatform.CustomJob(  # pylint: disable=unused-variable
              display_name="covertype_kfp_trial_job",
              worker_pool_specs=worker_pool_specs,
          )

          # TODO: launch the hyperparameter job using
          # aiplatform.HyperparameterTuningJob
          hp_job = None

          metrics = [
              trial.final_measurement.metrics[0].value for trial in hp_job.trials
          ]
          best_trial = hp_job.trials[metrics.index(max(metrics))]
          best_accuracy = float(best_trial.final_measurement.metrics[0].value)
          best_alpha = float(best_trial.parameters[0].value)
          best_max_iter = int(best_trial.parameters[1].value)

          return best_accuracy, best_alpha, best_max_iter

    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - tune_hyperparameters
